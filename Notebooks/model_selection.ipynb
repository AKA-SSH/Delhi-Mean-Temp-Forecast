{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a286d992-7793-4041-b3c5-f9db693bff85",
   "metadata": {},
   "source": [
    "# Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdfe4d9-28d4-4ba6-abe0-e9351cb4df68",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764448c3-98d4-4570-ad16-326a615fe5d3",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b18dd8a0-c3b6-48c0-b0ad-e27b2a03c982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data manipulation\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ensemble models and auto-tuning\n",
    "import optuna\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "\n",
    "# time-series models and auto-tuning\n",
    "from pmdarima import auto_arima\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "# evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "# WARNING\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe32263f-3182-4df2-93a3-9b49faa31ea3",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab3c5b65-4511-451c-894f-116c70a3159b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_object(file_name):\n",
    "    with open(file_name, 'rb') as f:\n",
    "        data= pickle.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2d2b350-11ea-4cd9-a4cc-468f9f701a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_object('notebook_artifacts/train_data.pkl')\n",
    "test_data = load_object('notebook_artifacts/test_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80df9440-6660-467f-a66a-111106bee159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meantemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>meanpressure</th>\n",
       "      <th>meantemp (t-1)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>7.400</td>\n",
       "      <td>92.000</td>\n",
       "      <td>2.980</td>\n",
       "      <td>1017.800</td>\n",
       "      <td>10.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>7.167</td>\n",
       "      <td>87.000</td>\n",
       "      <td>4.633</td>\n",
       "      <td>1018.667</td>\n",
       "      <td>7.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>8.667</td>\n",
       "      <td>71.333</td>\n",
       "      <td>1.233</td>\n",
       "      <td>1017.167</td>\n",
       "      <td>7.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>6.000</td>\n",
       "      <td>86.833</td>\n",
       "      <td>3.700</td>\n",
       "      <td>1016.500</td>\n",
       "      <td>8.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-06</th>\n",
       "      <td>7.000</td>\n",
       "      <td>82.800</td>\n",
       "      <td>1.480</td>\n",
       "      <td>1018.000</td>\n",
       "      <td>6.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            meantemp  humidity  wind_speed  meanpressure  meantemp (t-1)\n",
       "date                                                                    \n",
       "2013-01-02     7.400    92.000       2.980      1017.800          10.000\n",
       "2013-01-03     7.167    87.000       4.633      1018.667           7.400\n",
       "2013-01-04     8.667    71.333       1.233      1017.167           7.167\n",
       "2013-01-05     6.000    86.833       3.700      1016.500           8.667\n",
       "2013-01-06     7.000    82.800       1.480      1018.000           6.000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9761da-cd65-4bc7-b909-9e7e2639db94",
   "metadata": {},
   "source": [
    "# Performing Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70085933-96d1-4852-8d60-c06c279023e5",
   "metadata": {},
   "source": [
    "## Ensemble Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "819963d8-d125-4a35-ac46-03f0be4e8ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "X_train, y_train = train_data.drop('meantemp', axis=1), train_data['meantemp']\n",
    "# Define objective function\n",
    "def objective(trial):\n",
    "    # Choose regressor\n",
    "    regressor_name = trial.suggest_categorical('regressor', ['XGBoost', 'LightGBM', 'CatBoost', 'RandomForest', 'AdaBoost'])\n",
    "    \n",
    "    # Define hyperparameters\n",
    "    if regressor_name == 'XGBoost':\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
    "            'gamma': trial.suggest_loguniform('gamma', 0.01, 1.0),\n",
    "            'reg_alpha': trial.suggest_loguniform('reg_alpha', 0.01, 10.0),\n",
    "            'reg_lambda': trial.suggest_loguniform('reg_lambda', 0.01, 10.0)\n",
    "        }\n",
    "        regressor = XGBRegressor(**params, verbosity=0)\n",
    "    elif regressor_name == 'LightGBM':\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 2, 50)\n",
    "        }\n",
    "        regressor = LGBMRegressor(**params, verbosity=-1)\n",
    "    elif regressor_name == 'CatBoost':\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "            'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
    "            'depth': trial.suggest_int('depth', 3, 10)\n",
    "        }\n",
    "        regressor = CatBoostRegressor(**params, verbose= False)\n",
    "    elif regressor_name == 'RandomForest':\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10)\n",
    "        }\n",
    "        regressor = RandomForestRegressor(**params)\n",
    "    elif regressor_name == 'AdaBoost':\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "            'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1)\n",
    "        }\n",
    "        regressor = AdaBoostRegressor(**params)\n",
    "    \n",
    "    # Evaluate the regressor using cross-validation\n",
    "    score = -cross_val_score(regressor, X, y, scoring='neg_mean_squared_error', cv=5).mean()\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "478100f6-f5b2-435d-b7a2-b74308a51912",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-12 20:04:47,219] A new study created in memory with name: no-name-64a5aea5-f554-4c02-8705-a6ad13b449f1\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
      "[I 2024-02-12 20:04:47,681] Trial 0 finished with value: 2.120110864531192 and parameters: {'regressor': 'LightGBM', 'n_estimators': 376, 'max_depth': 4, 'learning_rate': 0.02939079206156143, 'num_leaves': 49}. Best is trial 0 with value: 2.120110864531192.\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1)\n",
      "[I 2024-02-12 20:04:49,373] Trial 1 finished with value: 2.8793049412760343 and parameters: {'regressor': 'AdaBoost', 'n_estimators': 115, 'learning_rate': 0.049947702302951494}. Best is trial 0 with value: 2.120110864531192.\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1)\n",
      "[I 2024-02-12 20:04:51,299] Trial 2 finished with value: 3.0922905550288826 and parameters: {'regressor': 'AdaBoost', 'n_estimators': 129, 'learning_rate': 0.005579092171936288}. Best is trial 0 with value: 2.120110864531192.\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:30: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
      "[I 2024-02-12 20:04:53,567] Trial 3 finished with value: 3.73738692393911 and parameters: {'regressor': 'CatBoost', 'n_estimators': 318, 'learning_rate': 0.006741484646879259, 'depth': 5}. Best is trial 0 with value: 2.120110864531192.\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'gamma': trial.suggest_loguniform('gamma', 0.01, 1.0),\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 0.01, 10.0),\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 0.01, 10.0)\n",
      "[I 2024-02-12 20:04:54,357] Trial 4 finished with value: 6.562011494781762 and parameters: {'regressor': 'XGBoost', 'n_estimators': 74, 'max_depth': 8, 'learning_rate': 0.01825794514837676, 'gamma': 0.01583530471818157, 'reg_alpha': 0.09731164729877714, 'reg_lambda': 2.4072229139009207}. Best is trial 0 with value: 2.120110864531192.\n",
      "[I 2024-02-12 20:04:56,363] Trial 5 finished with value: 3.0299774803413237 and parameters: {'regressor': 'RandomForest', 'n_estimators': 171, 'max_depth': 3}. Best is trial 0 with value: 2.120110864531192.\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
      "[I 2024-02-12 20:04:56,910] Trial 6 finished with value: 5.237549220929269 and parameters: {'regressor': 'LightGBM', 'n_estimators': 400, 'max_depth': 4, 'learning_rate': 0.003696073827137634, 'num_leaves': 17}. Best is trial 0 with value: 2.120110864531192.\n",
      "[I 2024-02-12 20:04:58,296] Trial 7 finished with value: 2.129735445884524 and parameters: {'regressor': 'RandomForest', 'n_estimators': 63, 'max_depth': 9}. Best is trial 0 with value: 2.120110864531192.\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'gamma': trial.suggest_loguniform('gamma', 0.01, 1.0),\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 0.01, 10.0),\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 0.01, 10.0)\n",
      "[I 2024-02-12 20:04:58,798] Trial 8 finished with value: 10.00788213731616 and parameters: {'regressor': 'XGBoost', 'n_estimators': 136, 'max_depth': 4, 'learning_rate': 0.007284994654435672, 'gamma': 0.2159424012809215, 'reg_alpha': 0.03189473981211578, 'reg_lambda': 0.06122629485270625}. Best is trial 0 with value: 2.120110864531192.\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
      "[I 2024-02-12 20:04:58,958] Trial 9 finished with value: 31.514705042979823 and parameters: {'regressor': 'LightGBM', 'n_estimators': 56, 'max_depth': 5, 'learning_rate': 0.005554877705155214, 'num_leaves': 33}. Best is trial 0 with value: 2.120110864531192.\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
      "[I 2024-02-12 20:05:00,485] Trial 10 finished with value: 19.68841388137393 and parameters: {'regressor': 'LightGBM', 'n_estimators': 476, 'max_depth': 6, 'learning_rate': 0.0012032314537952738, 'num_leaves': 49}. Best is trial 0 with value: 2.120110864531192.\n",
      "[I 2024-02-12 20:05:06,227] Trial 11 finished with value: 2.103323518536386 and parameters: {'regressor': 'RandomForest', 'n_estimators': 249, 'max_depth': 10}. Best is trial 11 with value: 2.103323518536386.\n",
      "[I 2024-02-12 20:05:12,264] Trial 12 finished with value: 2.1200378352286386 and parameters: {'regressor': 'RandomForest', 'n_estimators': 265, 'max_depth': 10}. Best is trial 11 with value: 2.103323518536386.\n",
      "[I 2024-02-12 20:05:17,586] Trial 13 finished with value: 2.1077997638169714 and parameters: {'regressor': 'RandomForest', 'n_estimators': 235, 'max_depth': 10}. Best is trial 11 with value: 2.103323518536386.\n",
      "[I 2024-02-12 20:05:22,680] Trial 14 finished with value: 2.109720945129439 and parameters: {'regressor': 'RandomForest', 'n_estimators': 227, 'max_depth': 10}. Best is trial 11 with value: 2.103323518536386.\n",
      "[I 2024-02-12 20:05:26,714] Trial 15 finished with value: 2.0758066063192944 and parameters: {'regressor': 'RandomForest', 'n_estimators': 204, 'max_depth': 8}. Best is trial 15 with value: 2.0758066063192944.\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:30: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
      "[I 2024-02-12 20:05:42,352] Trial 16 finished with value: 40.59361638090809 and parameters: {'regressor': 'CatBoost', 'n_estimators': 193, 'learning_rate': 0.0010538584513055873, 'depth': 10}. Best is trial 15 with value: 2.0758066063192944.\n",
      "[I 2024-02-12 20:05:48,405] Trial 17 finished with value: 2.0689949260404377 and parameters: {'regressor': 'RandomForest', 'n_estimators': 316, 'max_depth': 8}. Best is trial 17 with value: 2.0689949260404377.\n",
      "[I 2024-02-12 20:05:54,352] Trial 18 finished with value: 2.0516045133710783 and parameters: {'regressor': 'RandomForest', 'n_estimators': 337, 'max_depth': 7}. Best is trial 18 with value: 2.0516045133710783.\n",
      "[I 2024-02-12 20:05:59,980] Trial 19 finished with value: 2.0454877905915256 and parameters: {'regressor': 'RandomForest', 'n_estimators': 329, 'max_depth': 7}. Best is trial 19 with value: 2.0454877905915256.\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:30: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
      "[I 2024-02-12 20:06:01,685] Trial 20 finished with value: 2.1634332779812437 and parameters: {'regressor': 'CatBoost', 'n_estimators': 401, 'learning_rate': 0.08132718943908221, 'depth': 3}. Best is trial 19 with value: 2.0454877905915256.\n",
      "[I 2024-02-12 20:06:07,712] Trial 21 finished with value: 2.0471846786973016 and parameters: {'regressor': 'RandomForest', 'n_estimators': 332, 'max_depth': 7}. Best is trial 19 with value: 2.0454877905915256.\n",
      "[I 2024-02-12 20:06:13,348] Trial 22 finished with value: 2.0535207511359057 and parameters: {'regressor': 'RandomForest', 'n_estimators': 323, 'max_depth': 7}. Best is trial 19 with value: 2.0454877905915256.\n",
      "[I 2024-02-12 20:06:20,512] Trial 23 finished with value: 2.056973575352676 and parameters: {'regressor': 'RandomForest', 'n_estimators': 455, 'max_depth': 6}. Best is trial 19 with value: 2.0454877905915256.\n",
      "[I 2024-02-12 20:06:26,585] Trial 24 finished with value: 2.0490420400225307 and parameters: {'regressor': 'RandomForest', 'n_estimators': 352, 'max_depth': 7}. Best is trial 19 with value: 2.0454877905915256.\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1)\n",
      "[I 2024-02-12 20:06:31,763] Trial 25 finished with value: 3.0737097361836416 and parameters: {'regressor': 'AdaBoost', 'n_estimators': 362, 'learning_rate': 0.002369421000765008}. Best is trial 19 with value: 2.0454877905915256.\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'gamma': trial.suggest_loguniform('gamma', 0.01, 1.0),\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 0.01, 10.0),\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 0.01, 10.0)\n",
      "[I 2024-02-12 20:06:33,294] Trial 26 finished with value: 2.2389084808557285 and parameters: {'regressor': 'XGBoost', 'n_estimators': 287, 'max_depth': 7, 'learning_rate': 0.01457220943636282, 'gamma': 0.8227880445377849, 'reg_alpha': 8.450680623081427, 'reg_lambda': 0.012070581109857963}. Best is trial 19 with value: 2.0454877905915256.\n",
      "[I 2024-02-12 20:06:40,552] Trial 27 finished with value: 2.0681444607824444 and parameters: {'regressor': 'RandomForest', 'n_estimators': 434, 'max_depth': 6}. Best is trial 19 with value: 2.0454877905915256.\n",
      "[I 2024-02-12 20:06:45,984] Trial 28 finished with value: 2.081101472060829 and parameters: {'regressor': 'RandomForest', 'n_estimators': 287, 'max_depth': 8}. Best is trial 19 with value: 2.0454877905915256.\n",
      "[I 2024-02-12 20:06:50,970] Trial 29 finished with value: 2.1374494361931364 and parameters: {'regressor': 'RandomForest', 'n_estimators': 363, 'max_depth': 5}. Best is trial 19 with value: 2.0454877905915256.\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'gamma': trial.suggest_loguniform('gamma', 0.01, 1.0),\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 0.01, 10.0),\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 0.01, 10.0)\n",
      "[I 2024-02-12 20:06:53,396] Trial 30 finished with value: 13.794212179172444 and parameters: {'regressor': 'XGBoost', 'n_estimators': 400, 'max_depth': 7, 'learning_rate': 0.0021522502795541286, 'gamma': 0.011039191856406142, 'reg_alpha': 3.435800735938284, 'reg_lambda': 8.140255819912484}. Best is trial 19 with value: 2.0454877905915256.\n",
      "[I 2024-02-12 20:06:59,719] Trial 31 finished with value: 2.061166024083582 and parameters: {'regressor': 'RandomForest', 'n_estimators': 347, 'max_depth': 7}. Best is trial 19 with value: 2.0454877905915256.\n",
      "[I 2024-02-12 20:07:05,592] Trial 32 finished with value: 2.0500743741430476 and parameters: {'regressor': 'RandomForest', 'n_estimators': 339, 'max_depth': 7}. Best is trial 19 with value: 2.0454877905915256.\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1)\n",
      "[I 2024-02-12 20:07:09,173] Trial 33 finished with value: 2.784179873487379 and parameters: {'regressor': 'AdaBoost', 'n_estimators': 300, 'learning_rate': 0.09570965126502454}. Best is trial 19 with value: 2.0454877905915256.\n",
      "[I 2024-02-12 20:07:15,409] Trial 34 finished with value: 2.064108367725998 and parameters: {'regressor': 'RandomForest', 'n_estimators': 373, 'max_depth': 6}. Best is trial 19 with value: 2.0454877905915256.\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:30: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
      "[I 2024-02-12 20:07:52,530] Trial 35 finished with value: 2.2837905254061415 and parameters: {'regressor': 'CatBoost', 'n_estimators': 408, 'learning_rate': 0.04034523216310943, 'depth': 10}. Best is trial 19 with value: 2.0454877905915256.\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1)\n",
      "[I 2024-02-12 20:07:59,328] Trial 36 finished with value: 2.8858339424796395 and parameters: {'regressor': 'AdaBoost', 'n_estimators': 430, 'learning_rate': 0.014932100899208853}. Best is trial 19 with value: 2.0454877905915256.\n",
      "[I 2024-02-12 20:08:10,822] Trial 37 finished with value: 2.0918522965559943 and parameters: {'regressor': 'RandomForest', 'n_estimators': 497, 'max_depth': 9}. Best is trial 19 with value: 2.0454877905915256.\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
      "[I 2024-02-12 20:08:11,148] Trial 38 finished with value: 2.0803854883055046 and parameters: {'regressor': 'LightGBM', 'n_estimators': 348, 'max_depth': 8, 'learning_rate': 0.022832476182847002, 'num_leaves': 4}. Best is trial 19 with value: 2.0454877905915256.\n",
      "[I 2024-02-12 20:08:15,671] Trial 39 finished with value: 2.1407133110201984 and parameters: {'regressor': 'RandomForest', 'n_estimators': 309, 'max_depth': 5}. Best is trial 19 with value: 2.0454877905915256.\n",
      "[I 2024-02-12 20:08:21,833] Trial 40 finished with value: 2.0988295483636703 and parameters: {'regressor': 'RandomForest', 'n_estimators': 265, 'max_depth': 9}. Best is trial 19 with value: 2.0454877905915256.\n",
      "[I 2024-02-12 20:08:28,491] Trial 41 finished with value: 2.0490129751599673 and parameters: {'regressor': 'RandomForest', 'n_estimators': 335, 'max_depth': 7}. Best is trial 19 with value: 2.0454877905915256.\n",
      "[I 2024-02-12 20:08:34,561] Trial 42 finished with value: 2.0583010379430817 and parameters: {'regressor': 'RandomForest', 'n_estimators': 333, 'max_depth': 7}. Best is trial 19 with value: 2.0454877905915256.\n",
      "[I 2024-02-12 20:08:40,504] Trial 43 finished with value: 2.069158298131054 and parameters: {'regressor': 'RandomForest', 'n_estimators': 369, 'max_depth': 6}. Best is trial 19 with value: 2.0454877905915256.\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'gamma': trial.suggest_loguniform('gamma', 0.01, 1.0),\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 0.01, 10.0),\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 0.01, 10.0)\n",
      "[I 2024-02-12 20:08:45,375] Trial 44 finished with value: 2.3906390385260736 and parameters: {'regressor': 'XGBoost', 'n_estimators': 390, 'max_depth': 8, 'learning_rate': 0.00959708549474634, 'gamma': 0.06250807082021935, 'reg_alpha': 0.5306285986018217, 'reg_lambda': 0.5694221305313614}. Best is trial 19 with value: 2.0454877905915256.\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
      "[I 2024-02-12 20:08:46,328] Trial 45 finished with value: 21.193648574100557 and parameters: {'regressor': 'LightGBM', 'n_estimators': 299, 'max_depth': 7, 'learning_rate': 0.001780406520302601, 'num_leaves': 26}. Best is trial 19 with value: 2.0454877905915256.\n",
      "[I 2024-02-12 20:08:52,061] Trial 46 finished with value: 2.0592076549236156 and parameters: {'regressor': 'RandomForest', 'n_estimators': 275, 'max_depth': 8}. Best is trial 19 with value: 2.0454877905915256.\n",
      "[I 2024-02-12 20:08:58,515] Trial 47 finished with value: 2.0471955003600897 and parameters: {'regressor': 'RandomForest', 'n_estimators': 344, 'max_depth': 7}. Best is trial 19 with value: 2.0454877905915256.\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:30: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
      "[I 2024-02-12 20:09:04,199] Trial 48 finished with value: 7.236299936308384 and parameters: {'regressor': 'CatBoost', 'n_estimators': 426, 'learning_rate': 0.0032751157072781, 'depth': 7}. Best is trial 19 with value: 2.0454877905915256.\n",
      "[I 2024-02-12 20:09:10,667] Trial 49 finished with value: 2.0639919511910043 and parameters: {'regressor': 'RandomForest', 'n_estimators': 381, 'max_depth': 6}. Best is trial 19 with value: 2.0454877905915256.\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1)\n",
      "[I 2024-02-12 20:09:15,343] Trial 50 finished with value: 2.706976952936149 and parameters: {'regressor': 'AdaBoost', 'n_estimators': 320, 'learning_rate': 0.05927189605346303}. Best is trial 19 with value: 2.0454877905915256.\n",
      "[I 2024-02-12 20:09:21,647] Trial 51 finished with value: 2.0441105644627067 and parameters: {'regressor': 'RandomForest', 'n_estimators': 341, 'max_depth': 7}. Best is trial 51 with value: 2.0441105644627067.\n",
      "[I 2024-02-12 20:09:28,557] Trial 52 finished with value: 2.0474820520500385 and parameters: {'regressor': 'RandomForest', 'n_estimators': 354, 'max_depth': 7}. Best is trial 51 with value: 2.0441105644627067.\n",
      "[I 2024-02-12 20:09:34,260] Trial 53 finished with value: 2.070860350914659 and parameters: {'regressor': 'RandomForest', 'n_estimators': 329, 'max_depth': 6}. Best is trial 51 with value: 2.0441105644627067.\n",
      "[I 2024-02-12 20:09:40,169] Trial 54 finished with value: 2.0509233882437043 and parameters: {'regressor': 'RandomForest', 'n_estimators': 305, 'max_depth': 7}. Best is trial 51 with value: 2.0441105644627067.\n",
      "[I 2024-02-12 20:09:44,910] Trial 55 finished with value: 2.063153976242724 and parameters: {'regressor': 'RandomForest', 'n_estimators': 247, 'max_depth': 8}. Best is trial 51 with value: 2.0441105644627067.\n",
      "[I 2024-02-12 20:09:49,004] Trial 56 finished with value: 3.025439261511283 and parameters: {'regressor': 'RandomForest', 'n_estimators': 355, 'max_depth': 3}. Best is trial 51 with value: 2.0441105644627067.\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
      "[I 2024-02-12 20:09:49,188] Trial 57 finished with value: 2.1313897982365666 and parameters: {'regressor': 'LightGBM', 'n_estimators': 108, 'max_depth': 6, 'learning_rate': 0.032668577146472234, 'num_leaves': 9}. Best is trial 51 with value: 2.0441105644627067.\n",
      "[I 2024-02-12 20:09:57,707] Trial 58 finished with value: 2.08547722370964 and parameters: {'regressor': 'RandomForest', 'n_estimators': 386, 'max_depth': 9}. Best is trial 51 with value: 2.0441105644627067.\n",
      "[I 2024-02-12 20:10:03,017] Trial 59 finished with value: 2.053962163716768 and parameters: {'regressor': 'RandomForest', 'n_estimators': 281, 'max_depth': 7}. Best is trial 51 with value: 2.0441105644627067.\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'gamma': trial.suggest_loguniform('gamma', 0.01, 1.0),\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 0.01, 10.0),\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 0.01, 10.0)\n",
      "[I 2024-02-12 20:10:07,553] Trial 60 finished with value: 2.3631309604023203 and parameters: {'regressor': 'XGBoost', 'n_estimators': 332, 'max_depth': 8, 'learning_rate': 0.010650781644877672, 'gamma': 0.7682430574627519, 'reg_alpha': 0.014333970964579116, 'reg_lambda': 0.16078013146605413}. Best is trial 51 with value: 2.0441105644627067.\n",
      "[I 2024-02-12 20:10:15,396] Trial 61 finished with value: 2.0477337551790007 and parameters: {'regressor': 'RandomForest', 'n_estimators': 416, 'max_depth': 7}. Best is trial 51 with value: 2.0441105644627067.\n",
      "[I 2024-02-12 20:10:23,708] Trial 62 finished with value: 2.044318549552611 and parameters: {'regressor': 'RandomForest', 'n_estimators': 456, 'max_depth': 7}. Best is trial 51 with value: 2.0441105644627067.\n",
      "[I 2024-02-12 20:10:32,449] Trial 63 finished with value: 2.0460205746191 and parameters: {'regressor': 'RandomForest', 'n_estimators': 453, 'max_depth': 7}. Best is trial 51 with value: 2.0441105644627067.\n",
      "[I 2024-02-12 20:10:39,804] Trial 64 finished with value: 2.0585558156203394 and parameters: {'regressor': 'RandomForest', 'n_estimators': 451, 'max_depth': 6}. Best is trial 51 with value: 2.0441105644627067.\n",
      "[I 2024-02-12 20:10:49,859] Trial 65 finished with value: 2.063639811007114 and parameters: {'regressor': 'RandomForest', 'n_estimators': 471, 'max_depth': 8}. Best is trial 51 with value: 2.0441105644627067.\n",
      "[I 2024-02-12 20:10:58,205] Trial 66 finished with value: 2.0555275295324034 and parameters: {'regressor': 'RandomForest', 'n_estimators': 448, 'max_depth': 7}. Best is trial 51 with value: 2.0441105644627067.\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:30: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
      "[I 2024-02-12 20:11:04,808] Trial 67 finished with value: 5.2026492010356105 and parameters: {'regressor': 'CatBoost', 'n_estimators': 500, 'learning_rate': 0.003430226174583153, 'depth': 7}. Best is trial 51 with value: 2.0441105644627067.\n",
      "[I 2024-02-12 20:11:13,712] Trial 68 finished with value: 2.043845633746705 and parameters: {'regressor': 'RandomForest', 'n_estimators': 476, 'max_depth': 7}. Best is trial 68 with value: 2.043845633746705.\n",
      "[I 2024-02-12 20:11:23,630] Trial 69 finished with value: 2.071543792162662 and parameters: {'regressor': 'RandomForest', 'n_estimators': 465, 'max_depth': 8}. Best is trial 68 with value: 2.043845633746705.\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1)\n",
      "[I 2024-02-12 20:11:30,723] Trial 70 finished with value: 3.095120737251414 and parameters: {'regressor': 'AdaBoost', 'n_estimators': 438, 'learning_rate': 0.0015510986921202041}. Best is trial 68 with value: 2.043845633746705.\n",
      "[I 2024-02-12 20:11:38,613] Trial 71 finished with value: 2.0505409172682434 and parameters: {'regressor': 'RandomForest', 'n_estimators': 416, 'max_depth': 7}. Best is trial 68 with value: 2.043845633746705.\n",
      "[I 2024-02-12 20:11:47,375] Trial 72 finished with value: 2.051380129715159 and parameters: {'regressor': 'RandomForest', 'n_estimators': 487, 'max_depth': 7}. Best is trial 68 with value: 2.043845633746705.\n",
      "[I 2024-02-12 20:11:56,507] Trial 73 finished with value: 2.0476792585601626 and parameters: {'regressor': 'RandomForest', 'n_estimators': 478, 'max_depth': 7}. Best is trial 68 with value: 2.043845633746705.\n",
      "[I 2024-02-12 20:12:04,111] Trial 74 finished with value: 2.061002621861134 and parameters: {'regressor': 'RandomForest', 'n_estimators': 463, 'max_depth': 6}. Best is trial 68 with value: 2.043845633746705.\n",
      "[I 2024-02-12 20:12:13,250] Trial 75 finished with value: 2.050686497056797 and parameters: {'regressor': 'RandomForest', 'n_estimators': 485, 'max_depth': 7}. Best is trial 68 with value: 2.043845633746705.\n",
      "[I 2024-02-12 20:12:20,629] Trial 76 finished with value: 2.0462996884497544 and parameters: {'regressor': 'RandomForest', 'n_estimators': 399, 'max_depth': 7}. Best is trial 68 with value: 2.043845633746705.\n",
      "[I 2024-02-12 20:12:29,625] Trial 77 finished with value: 2.0592985307852487 and parameters: {'regressor': 'RandomForest', 'n_estimators': 440, 'max_depth': 8}. Best is trial 68 with value: 2.043845633746705.\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
      "[I 2024-02-12 20:12:30,717] Trial 78 finished with value: 2.1756510773467292 and parameters: {'regressor': 'LightGBM', 'n_estimators': 406, 'max_depth': 7, 'learning_rate': 0.03063064991759127, 'num_leaves': 34}. Best is trial 68 with value: 2.043845633746705.\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'gamma': trial.suggest_loguniform('gamma', 0.01, 1.0),\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 0.01, 10.0),\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 0.01, 10.0)\n",
      "[I 2024-02-12 20:12:32,517] Trial 79 finished with value: 2.2203066053476426 and parameters: {'regressor': 'XGBoost', 'n_estimators': 395, 'max_depth': 5, 'learning_rate': 0.022764666349858367, 'gamma': 0.08791396997798584, 'reg_alpha': 0.7421579724765653, 'reg_lambda': 0.01666373209617248}. Best is trial 68 with value: 2.043845633746705.\n",
      "[I 2024-02-12 20:12:39,522] Trial 80 finished with value: 2.059710411156499 and parameters: {'regressor': 'RandomForest', 'n_estimators': 422, 'max_depth': 6}. Best is trial 68 with value: 2.043845633746705.\n",
      "[I 2024-02-12 20:12:46,356] Trial 81 finished with value: 2.059045293299037 and parameters: {'regressor': 'RandomForest', 'n_estimators': 358, 'max_depth': 7}. Best is trial 68 with value: 2.043845633746705.\n",
      "[I 2024-02-12 20:12:53,584] Trial 82 finished with value: 2.0628493024266996 and parameters: {'regressor': 'RandomForest', 'n_estimators': 379, 'max_depth': 7}. Best is trial 68 with value: 2.043845633746705.\n",
      "[I 2024-02-12 20:12:59,765] Trial 83 finished with value: 2.0539303769724135 and parameters: {'regressor': 'RandomForest', 'n_estimators': 347, 'max_depth': 7}. Best is trial 68 with value: 2.043845633746705.\n",
      "[I 2024-02-12 20:13:07,356] Trial 84 finished with value: 2.072340327736753 and parameters: {'regressor': 'RandomForest', 'n_estimators': 366, 'max_depth': 8}. Best is trial 68 with value: 2.043845633746705.\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:30: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
      "[I 2024-02-12 20:13:09,110] Trial 85 finished with value: 2.129680187794748 and parameters: {'regressor': 'CatBoost', 'n_estimators': 297, 'learning_rate': 0.06498827738308242, 'depth': 3}. Best is trial 68 with value: 2.043845633746705.\n",
      "[I 2024-02-12 20:13:15,145] Trial 86 finished with value: 2.053751598664609 and parameters: {'regressor': 'RandomForest', 'n_estimators': 315, 'max_depth': 7}. Best is trial 68 with value: 2.043845633746705.\n",
      "[I 2024-02-12 20:13:23,997] Trial 87 finished with value: 2.055265523389042 and parameters: {'regressor': 'RandomForest', 'n_estimators': 461, 'max_depth': 7}. Best is trial 68 with value: 2.043845633746705.\n",
      "[I 2024-02-12 20:13:29,910] Trial 88 finished with value: 2.0565662695535343 and parameters: {'regressor': 'RandomForest', 'n_estimators': 345, 'max_depth': 6}. Best is trial 68 with value: 2.043845633746705.\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:43: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1)\n",
      "[I 2024-02-12 20:13:35,372] Trial 89 finished with value: 2.7093708043290707 and parameters: {'regressor': 'AdaBoost', 'n_estimators': 375, 'learning_rate': 0.04335118595217984}. Best is trial 68 with value: 2.043845633746705.\n",
      "[I 2024-02-12 20:13:41,512] Trial 90 finished with value: 2.0521612307817234 and parameters: {'regressor': 'RandomForest', 'n_estimators': 327, 'max_depth': 7}. Best is trial 68 with value: 2.043845633746705.\n",
      "[I 2024-02-12 20:13:50,737] Trial 91 finished with value: 2.0536830256514946 and parameters: {'regressor': 'RandomForest', 'n_estimators': 489, 'max_depth': 7}. Best is trial 68 with value: 2.043845633746705.\n",
      "[I 2024-02-12 20:13:58,916] Trial 92 finished with value: 2.050583431575056 and parameters: {'regressor': 'RandomForest', 'n_estimators': 447, 'max_depth': 7}. Best is trial 68 with value: 2.043845633746705.\n",
      "[I 2024-02-12 20:14:08,836] Trial 93 finished with value: 2.0676475193873167 and parameters: {'regressor': 'RandomForest', 'n_estimators': 478, 'max_depth': 8}. Best is trial 68 with value: 2.043845633746705.\n",
      "[I 2024-02-12 20:14:16,403] Trial 94 finished with value: 2.0687430794066435 and parameters: {'regressor': 'RandomForest', 'n_estimators': 455, 'max_depth': 6}. Best is trial 68 with value: 2.043845633746705.\n",
      "[I 2024-02-12 20:14:25,536] Trial 95 finished with value: 2.047844455900446 and parameters: {'regressor': 'RandomForest', 'n_estimators': 476, 'max_depth': 7}. Best is trial 68 with value: 2.043845633746705.\n",
      "[I 2024-02-12 20:14:33,537] Trial 96 finished with value: 2.044074738674509 and parameters: {'regressor': 'RandomForest', 'n_estimators': 434, 'max_depth': 7}. Best is trial 68 with value: 2.043845633746705.\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:23: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
      "[I 2024-02-12 20:14:34,482] Trial 97 finished with value: 2.729887144130634 and parameters: {'regressor': 'LightGBM', 'n_estimators': 427, 'max_depth': 7, 'learning_rate': 0.0053806080163154935, 'num_leaves': 17}. Best is trial 68 with value: 2.043845633746705.\n",
      "[I 2024-02-12 20:14:42,174] Trial 98 finished with value: 2.046986006694415 and parameters: {'regressor': 'RandomForest', 'n_estimators': 408, 'max_depth': 7}. Best is trial 68 with value: 2.043845633746705.\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:13: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.001, 0.1),\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:14: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'gamma': trial.suggest_loguniform('gamma', 0.01, 1.0),\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:15: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_alpha': trial.suggest_loguniform('reg_alpha', 0.01, 10.0),\n",
      "C:\\Users\\Akash\\AppData\\Local\\Temp\\ipykernel_7120\\36614773.py:16: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'reg_lambda': trial.suggest_loguniform('reg_lambda', 0.01, 10.0)\n",
      "[I 2024-02-12 20:14:45,126] Trial 99 finished with value: 4.041785018189994 and parameters: {'regressor': 'XGBoost', 'n_estimators': 404, 'max_depth': 6, 'learning_rate': 0.004352649534420437, 'gamma': 0.033311393150104604, 'reg_alpha': 0.15190464657008984, 'reg_lambda': 0.8065500846565135}. Best is trial 68 with value: 2.043845633746705.\n"
     ]
    }
   ],
   "source": [
    "# Optimize hyperparameters\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79fd847f-8a02-4ba9-9408-bfa9cd5f696f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "Value:  2.043845633746705\n",
      "Params: \n",
      "    regressor: RandomForest\n",
      "    n_estimators: 476\n",
      "    max_depth: 7\n"
     ]
    }
   ],
   "source": [
    "# Print the best hyperparameters\n",
    "print('Best trial:')\n",
    "best_trial = study.best_trial\n",
    "print('Value: ', best_trial.value)\n",
    "print('Params: ')\n",
    "for key, value in best_trial.params.items():\n",
    "    print(f'    {key}: {value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153da774-bebf-4886-9791-376f7083cad3",
   "metadata": {},
   "source": [
    "## Timer Series Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "190b992f-d4b9-40ae-ad90-f58c99a06fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_split_train, X_split_test, y_split_train, y_split_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df994de4-886b-4a37-9a96-84dcfce861ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_tune_time_series(train_data):\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"statsmodels\")\n",
    "    X_train, y_train = train_data.drop('meantemp', axis=1), train_data['meantemp']\n",
    "    arima_model = auto_arima(y_split_train, X=X_split_train, seasonal=True, suppress_warnings=True)\n",
    "    best_model = SARIMAX(y_split_train, order=arima_model.order, seasonal_order=arima_model.seasonal_order, exog=X_split_train).fit(disp=False)\n",
    "    predictions = best_model.get_forecast(steps=len(X_split_test), exog=X_split_test).predicted_mean\n",
    "    warnings.resetwarnings()\n",
    "    return best_model, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c41ba80-0f1c-48aa-b148-cab413fb2790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2.615749346108933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akash\\Desktop\\ML\\MeanTemp\\.venv\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n"
     ]
    }
   ],
   "source": [
    "best_model, predictions = auto_tune_time_series(train_data)\n",
    "mse = mean_squared_error(y_split_test, predictions)\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddb1664-e358-4a6e-ad77-843a3f4d13ed",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b04d9fe-fe4b-4945-aa0f-4efae59d1be1",
   "metadata": {},
   "source": [
    "- Selected Model: Random Forest Regressor.\n",
    "- Below are the hyperparameters:\n",
    "  - n_estimators: 476\n",
    "  -  max_depth: 7\n",
    "- MSE: 2.0447"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
